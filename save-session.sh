#!/bin/bash
# Claude Code Session Auto-Save Hook
# Auto-saves Claude session history to project directory as readable markdown files
# è‡ªåŠ¨ä¿å­˜ Claude ä¼šè¯å†å²åˆ°é¡¹ç›®ç›®å½•ï¼Œç”Ÿæˆå¯è¯»çš„ markdown æ–‡ä»¶
#
# Features / åŠŸèƒ½:
# - Full conversation export with merged consecutive messages / å…¨é‡å¯¼å‡ºï¼Œåˆå¹¶è¿ç»­æ¶ˆæ¯
# - Large file async background processing / å¤§æ–‡ä»¶åå°å¼‚æ­¥å¤„ç†
# - Atomic file updates (temp file + mv) / åŸå­æ›´æ–°ï¼ˆä¸´æ—¶æ–‡ä»¶ + mvï¼‰
# - System timezone auto-detection / è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿæ—¶åŒº
# - System tags filtering / è¿‡æ»¤ç³»ç»Ÿæ ‡ç­¾

INPUT=$(cat)

PROJECT_DIR="${CLAUDE_PROJECT_DIR:-$(echo "$INPUT" | jq -r '.cwd // empty' 2>/dev/null)}"
[ -z "$PROJECT_DIR" ] || [ "$PROJECT_DIR" = "null" ] && exit 0

PROJECT_HASH=$(echo "$PROJECT_DIR" | sed 's/[/ ]/-/g')
CLAUDE_SESSIONS_DIR="$HOME/.claude/projects/$PROJECT_HASH"
BACKUP_DIR="$PROJECT_DIR/.claude/session-history"

[ ! -d "$CLAUDE_SESSIONS_DIR" ] && exit 0

mkdir -p "$BACKUP_DIR"

# Background mode flag (passed by main process when spawning background worker)
# åå°æ¨¡å¼æ ‡å¿—ï¼ˆç”±ä¸»è¿›ç¨‹å¯åŠ¨åå°è¿›ç¨‹æ—¶ä¼ å…¥ï¼‰
BACKGROUND_MODE="${1:-}"

# Temp directory for atomic updates / ä¸´æ—¶ç›®å½•ç”¨äºåŸå­æ›´æ–°
TMP_DIR="$BACKUP_DIR/.tmp_$$"
mkdir -p "$TMP_DIR"
trap "rm -rf '$TMP_DIR'" EXIT

# Clean up stale temp directories (older than 1 hour) / æ¸…ç†æ®‹ç•™çš„ä¸´æ—¶ç›®å½•ï¼ˆè¶…è¿‡1å°æ—¶çš„ï¼‰
find "$BACKUP_DIR" -maxdepth 1 -name ".tmp_*" -type d -mmin +60 -exec rm -rf {} \; 2>/dev/null

# Get system timezone offset in hours / è·å–ç³»ç»Ÿæ—¶åŒºåç§»ï¼ˆå°æ—¶ï¼‰
get_tz_offset() {
    local offset_sec=$(date +%z | sed 's/\([+-]\)\([0-9][0-9]\)\([0-9][0-9]\)/\1\2*3600+\1\3*60/' | bc 2>/dev/null)
    [ -z "$offset_sec" ] && offset_sec=28800  # Default +8 / é»˜è®¤ +8
    echo $((offset_sec / 3600))
}
TZ_OFFSET=$(get_tz_offset)

# Ensure session-history directory is git-ignored / ç¡®ä¿ session-history ç›®å½•è¢« git å¿½ç•¥
GITIGNORE="$PROJECT_DIR/.gitignore"
if [ -d "$PROJECT_DIR/.git" ] && [ -f "$GITIGNORE" ]; then
    # Check if .claude/ or .claude/session-history/ is already ignored
    # æ£€æŸ¥æ˜¯å¦å·²å¿½ç•¥ .claude/ æˆ– .claude/session-history/
    if ! grep -qE '^/?\.claude/?$|^/?\.claude/session-history/?$' "$GITIGNORE" 2>/dev/null; then
        echo "" >> "$GITIGNORE"
        echo "# Claude session history (auto-added)" >> "$GITIGNORE"
        echo ".claude/session-history/" >> "$GITIGNORE"
    fi
elif [ -d "$PROJECT_DIR/.git" ] && [ ! -f "$GITIGNORE" ]; then
    # No .gitignore exists, create one / æ²¡æœ‰ .gitignoreï¼Œåˆ›å»ºä¸€ä¸ª
    echo "# Claude session history (auto-added)" > "$GITIGNORE"
    echo ".claude/session-history/" >> "$GITIGNORE"
fi

# Throttling: 10s cooldown + simple lock to prevent concurrent runs
# èŠ‚æµï¼š10ç§’å†·å´ + ç®€å•é”é˜²å¹¶å‘
LOCK_FILE="$BACKUP_DIR/.lock"
LOCK_PID_FILE="$BACKUP_DIR/.lock_pid"
BG_PID_FILE="$BACKUP_DIR/.bg_pid"

# Background mode skips throttle check / åå°æ¨¡å¼è·³è¿‡èŠ‚æµæ£€æŸ¥
if [ "$BACKGROUND_MODE" != "--background" ]; then
    # Check if another process is running / æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹åœ¨è¿è¡Œ
    if [ -f "$LOCK_PID_FILE" ]; then
        old_pid=$(cat "$LOCK_PID_FILE" 2>/dev/null)
        if [ -n "$old_pid" ] && kill -0 "$old_pid" 2>/dev/null; then
            exit 0
        fi
    fi
    echo $$ > "$LOCK_PID_FILE"

    if [ -f "$LOCK_FILE" ]; then
        last_run=$(cat "$LOCK_FILE" 2>/dev/null || echo 0)
        if [ $(($(date +%s) - last_run)) -lt 10 ]; then
            rm -f "$LOCK_PID_FILE"
            exit 0
        fi
    fi

    date +%s > "$LOCK_FILE"
fi

# Convert UTC timestamp to local timezone / UTC è½¬æœ¬åœ°æ—¶åŒº
utc_to_local() {
    local ts="$1"
    [ -z "$ts" ] || [ "$ts" = "null" ] && return
    local h=$((10#${ts:11:2} + TZ_OFFSET))
    local d="${ts:0:10}"
    if [ $h -ge 24 ]; then
        h=$((h-24))
        d=$(date -j -v+1d -f "%Y-%m-%d" "$d" "+%Y-%m-%d" 2>/dev/null || echo "$d")
    elif [ $h -lt 0 ]; then
        h=$((h+24))
        d=$(date -j -v-1d -f "%Y-%m-%d" "$d" "+%Y-%m-%d" 2>/dev/null || echo "$d")
    fi
    printf "%s %02d:%s" "$d" "$h" "${ts:14:2}"
}

for jsonl_file in "$CLAUDE_SESSIONS_DIR"/*.jsonl; do
    [ -f "$jsonl_file" ] || continue

    # Skip empty sessions (need at least one user message and one assistant reply)
    # è·³è¿‡ç©ºä¼šè¯ï¼ˆè‡³å°‘éœ€è¦æœ‰ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å’Œä¸€æ¡åŠ©æ‰‹å›å¤ï¼‰
    # Use grep for fast detection, avoid loading entire file with jq -s
    # ç”¨ grep å¿«é€Ÿæ£€æµ‹ï¼Œé¿å… jq -s åŠ è½½æ•´ä¸ªæ–‡ä»¶
    grep -q '"type":"user"' "$jsonl_file" || continue
    grep -q '"type":"assistant"' "$jsonl_file" || continue

    # Large file handling: spawn background process for files > 2MB
    # å¤§æ–‡ä»¶å¤„ç†ï¼šè¶…è¿‡ 2MB çš„æ–‡ä»¶å¯åŠ¨åå°è¿›ç¨‹å¤„ç†
    file_size=$(stat -f %z "$jsonl_file" 2>/dev/null || echo 0)
    if [ "$file_size" -gt 2097152 ] && [ "$BACKGROUND_MODE" != "--background" ]; then
        large_file_lock="$BACKUP_DIR/.large_$(basename "$jsonl_file" .jsonl)"

        # Check if background process is already running / æ£€æŸ¥æ˜¯å¦å·²æœ‰åå°è¿›ç¨‹åœ¨å¤„ç†
        if [ -f "$BG_PID_FILE" ]; then
            bg_pid=$(cat "$BG_PID_FILE" 2>/dev/null)
            if [ -n "$bg_pid" ] && kill -0 "$bg_pid" 2>/dev/null; then
                # Background process still running, skip / åå°è¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼Œè·³è¿‡
                continue
            fi
        fi

        # 5-minute throttle for large files / å¤§æ–‡ä»¶5åˆ†é’ŸèŠ‚æµ
        if [ -f "$large_file_lock" ]; then
            last_large=$(cat "$large_file_lock" 2>/dev/null || echo 0)
            if [ $(($(date +%s) - last_large)) -lt 300 ]; then
                continue
            fi
        fi
        date +%s > "$large_file_lock"

        # Spawn background process (use nohup to detach from terminal)
        # å¯åŠ¨åå°è¿›ç¨‹å¤„ç†å¤§æ–‡ä»¶ï¼ˆç”¨ nohup ç¡®ä¿è„±ç¦»ç»ˆç«¯ï¼‰
        nohup bash -c "
            export CLAUDE_PROJECT_DIR='$PROJECT_DIR'
            export BACKUP_DIR='$BACKUP_DIR'
            export CLAUDE_SESSIONS_DIR='$CLAUDE_SESSIONS_DIR'
            '$0' --background
        " &>/dev/null &
        echo $! > "$BG_PID_FILE"

        # Main process skips this file, continue with smaller files
        # ä¸»è¿›ç¨‹è·³è¿‡æ­¤æ–‡ä»¶ï¼Œç»§ç»­å¤„ç†å…¶ä»–å°æ–‡ä»¶
        continue
    fi

    session_id=$(basename "$jsonl_file" .jsonl)
    short_id="${session_id:0:4}"

    # Get session title / è·å–ä¼šè¯æ ‡é¢˜
    # 1. Prefer title from existing md file (preserve user edits)
    #    ä¼˜å…ˆä»å·²æœ‰ md æ–‡ä»¶è¯»å–æ ‡é¢˜ï¼ˆä¿ç•™ç”¨æˆ·ä¿®æ”¹ï¼‰
    # 2. Otherwise use first user message / å¦åˆ™ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    session_title=""
    old_file=""
    old_tools_file=""

    # Find existing md file for this session (via .session_map)
    # æŸ¥æ‰¾å±äºå½“å‰ session çš„ md æ–‡ä»¶ï¼ˆé€šè¿‡ .session_map æ˜ å°„ï¼‰
    session_map="$BACKUP_DIR/.session_map"
    existing_file=$(grep "^${session_id}=" "$session_map" 2>/dev/null | cut -d'=' -f2-)

    if [ -n "$existing_file" ] && [ -f "$existing_file" ]; then
        # Read title from existing file (first line without #)
        # ä»å·²æœ‰æ–‡ä»¶è¯»å–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œå»æ‰ # ï¼‰
        session_title=$(head -1 "$existing_file" | sed 's/^# //')
        old_file="$existing_file"
        old_tools_file=$(echo "$existing_file" | sed 's/\[History\]/[ToolUse]/')
    fi

    if [ -z "$session_title" ]; then
        # Get first user message content (skip <xxx> system tags)
        # è·å–ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­çš„çœŸå®å†…å®¹ï¼ˆè·³è¿‡ <xxx> ç³»ç»Ÿæ ‡ç­¾ï¼‰
        session_title=$(jq -r 'select(.type == "user") | .message.content | if type == "array" then .[] | select(type == "object" and .type == "text") | .text else . end' "$jsonl_file" 2>/dev/null | grep -v '^<' | grep -v '^$' | head -1 | cut -c1-50 | tr '\n' ' ')
    fi

    # Title fallback: check for empty, whitespace-only, null, or garbled
    # æ ‡é¢˜å®¹é”™ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºç©ºã€çº¯ç©ºæ ¼ã€null æˆ–ä¹±ç 
    clean_title=$(echo "$session_title" | tr -cd '[:print:]' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
    if [ -z "$clean_title" ] || [ "$clean_title" = "null" ] || [ ${#clean_title} -lt 2 ]; then
        session_title="Session_${short_id}"
    else
        session_title="$clean_title"
    fi

    safe_title=$(echo "$session_title" | sed 's/[\/\\:*?"<>|]/-/g' | sed 's/  */ /g' | sed 's/^ *//;s/ *$//')
    [ -z "$safe_title" ] && safe_title="untitled"

    start_time=$(head -1 "$jsonl_file" | jq -r '.timestamp // empty' 2>/dev/null)
    formatted_start=$(utc_to_local "$start_time")
    [ -z "$formatted_start" ] && formatted_start="Unknown"

    # Filename time format: MM-DD_HHMM / æ–‡ä»¶åç”¨çš„æ—¶é—´æ ¼å¼ï¼šMM-DD_HHMM
    file_time=$(echo "$formatted_start" | sed 's/^[0-9]*-//' | sed 's/ /_/' | sed 's/://')
    [ -z "$file_time" ] || [ "$file_time" = "Unknown" ] && file_time="unknown"

    # Filename format: [History]title_time_id.md / æ–‡ä»¶åæ ¼å¼ï¼š[History]æ ‡é¢˜_æ—¶é—´_id.md
    md_file="$BACKUP_DIR/[History]${safe_title}_${file_time}_${short_id}.md"
    tools_file="$BACKUP_DIR/[ToolUse]${safe_title}_${file_time}_${short_id}.md"
    compact_file="$BACKUP_DIR/[Compact]${safe_title}_${file_time}_${short_id}.md"

    # Temp file paths for atomic update / ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåŸå­æ›´æ–°ï¼‰
    tmp_md_file="$TMP_DIR/[History]${safe_title}_${file_time}_${short_id}.md"
    tmp_tools_file="$TMP_DIR/[ToolUse]${safe_title}_${file_time}_${short_id}.md"
    tmp_compact_file="$TMP_DIR/[Compact]${safe_title}_${file_time}_${short_id}.md"

    # Skip if source file is not newer than output / æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦æ¯”è¾“å‡ºæ–‡ä»¶æ–°ï¼ˆè·³è¿‡æ— å˜åŒ–çš„ï¼‰
    if [ -f "$md_file" ]; then
        src_mtime=$(stat -f %m "$jsonl_file" 2>/dev/null)
        dst_mtime=$(stat -f %m "$md_file" 2>/dev/null)
        [ "$src_mtime" -le "$dst_mtime" ] && continue
    fi

    # Generate conversation header (write to temp file)
    # ç”Ÿæˆä¼šè¯è®°å½•å¤´éƒ¨ï¼ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶ï¼‰
    cat > "$tmp_md_file" << EOF
# ${session_title}
> Started: ${formatted_start}
> [View Tool Details]([ToolUse]${safe_title}_${file_time}_${short_id}.md)

---

EOF

    # Save session_id to file mapping (for reading user-modified titles next time)
    # ä¿å­˜ session_id åˆ°æ–‡ä»¶çš„æ˜ å°„ï¼ˆç”¨äºä¸‹æ¬¡è¯»å–ç”¨æˆ·ä¿®æ”¹çš„æ ‡é¢˜ï¼‰
    grep -v "^${session_id}=" "$session_map" > "${session_map}.tmp" 2>/dev/null || true
    echo "${session_id}=${md_file}" >> "${session_map}.tmp"
    mv "${session_map}.tmp" "$session_map"

    # Generate tool details header (write to temp file)
    # ç”Ÿæˆå·¥å…·è¯¦æƒ…å¤´éƒ¨ï¼ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶ï¼‰
    cat > "$tmp_tools_file" << EOF
# Tool Details - ${session_title}
> [Back to Conversation]([History]${safe_title}_${file_time}_${short_id}.md)

---

EOF

    # Extract tool call details / æå–å·¥å…·è°ƒç”¨è¯¦æƒ…
    jq -c 'select(.type == "assistant") | select(.message.content != null) | {timestamp: .timestamp, tools: [.message.content[] | select(.type == "tool_use")]} | .tools[] as $tool | {timestamp, tool: $tool}' "$jsonl_file" 2>/dev/null | while read -r tool_entry; do
        timestamp=$(echo "$tool_entry" | jq -r '.timestamp // ""')
        tool=$(echo "$tool_entry" | jq -r '.tool')
        tool_name=$(echo "$tool" | jq -r '.name // "unknown"')
        tool_id=$(echo "$tool" | jq -r '.id // "unknown"')

        formatted_time=$(utc_to_local "$timestamp")
        time_only="${formatted_time:11:5}"

        # Truncation warning / æˆªæ–­æç¤º
        tool_input_raw=$(echo "$tool" | jq -r '.input | tojson' 2>/dev/null)
        if [ ${#tool_input_raw} -gt 5000 ]; then
            tool_input="${tool_input_raw:0:5000}...\n\n> âš ï¸ Content truncated (original: ${#tool_input_raw} chars)"
        else
            tool_input="$tool_input_raw"
        fi

        cat >> "$tmp_tools_file" << EOF
## ${tool_name} - ${time_only}
<a id="tool-${tool_id}"></a>

\`\`\`json
${tool_input}
\`\`\`

---

EOF
    done

    # Extract and format conversation (merge consecutive messages, separate compact summary)
    # æå–å¹¶æ ¼å¼åŒ–å¯¹è¯ï¼ˆåˆå¹¶è¿ç»­æ¶ˆæ¯ï¼Œåˆ†ç¦» compact summaryï¼‰
    # First detect if there's a compact summary / å…ˆæ£€æµ‹æ˜¯å¦æœ‰ compact summary
    has_compact=$(jq -r 'select(.type == "user") | .message.content | if type == "array" then .[] | select(.type == "text") | .text else . end' "$jsonl_file" 2>/dev/null | grep -c "This session is being continued from a previous conversation" 2>/dev/null | tail -1)
    [ -z "$has_compact" ] && has_compact=0

    if [ "$has_compact" -gt 0 ]; then
        # Generate compact file header (write to temp file)
        # ç”Ÿæˆ compact æ–‡ä»¶å¤´éƒ¨ï¼ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶ï¼‰
        cat > "$tmp_compact_file" << EOF
# Compact Summary - ${session_title}
> [Back to Conversation]([History]${safe_title}_${file_time}_${short_id}.md)

---

EOF
        # Extract compact summary content / æå– compact summary å†…å®¹
        jq -r 'select(.type == "user") | .message.content | if type == "array" then .[] | select(.type == "text") | .text else . end' "$jsonl_file" 2>/dev/null | grep -A 10000 "This session is being continued from a previous conversation" | head -n 500 >> "$tmp_compact_file"
    fi

    jq -rs --arg tools_file "[ToolUse]${safe_title}_${file_time}_${short_id}.md" --arg compact_file "[Compact]${safe_title}_${file_time}_${short_id}.md" --argjson tz_offset "$TZ_OFFSET" '
        # Function: clean system tags / å‡½æ•°ï¼šæ¸…ç†ç³»ç»Ÿæ ‡ç­¾
        def clean_system_tags:
            gsub("<system-reminder>[\\s\\S]*?</system-reminder>"; "") |
            gsub("<ide_opened_file>[\\s\\S]*?</ide_opened_file>"; "") |
            gsub("<user-prompt-submit-hook>[\\s\\S]*?</user-prompt-submit-hook>"; "") |
            gsub("^\\s+|\\s+$"; "");

        [.[] | select(.type == "user" or .type == "assistant") | select(.message != null) |
        {
            type: .type,
            timestamp: .timestamp,
            content: (
                if .message.content then
                    if (.message.content | type) == "array" then
                        [.message.content[] |
                            if type == "string" then . | clean_system_tags
                            elif .type == "text" then
                                # Replace compact summary with prominent link placeholder
                                # compact summary æ›¿æ¢ä¸ºé†’ç›®çš„é“¾æ¥å ä½ç¬¦
                                if (.text | contains("This session is being continued from a previous conversation")) then
                                    "\n---\n\n## ğŸ“¦ Context Compaction\n\n> **Session context was compressed at this point.**\n> Previous conversation summary available below.\n\nâ¡ï¸ **[View Full Compact Summary](\($compact_file))**\n\n---\n"
                                else .text | clean_system_tags
                                end
                            elif .type == "tool_use" then "ğŸ”§ [\(.name)](\($tools_file)#tool-\(.id))"
                            else null
                            end
                        ] | map(select(. != null and . != "")) | join("\n")
                    else
                        # Non-array content also check for compact
                        # éæ•°ç»„å†…å®¹ä¹Ÿæ£€æŸ¥ compact
                        if (.message.content | contains("This session is being continued from a previous conversation")) then
                            "\n---\n\n## ğŸ“¦ Context Compaction\n\n> **Session context was compressed at this point.**\n> Previous conversation summary available below.\n\nâ¡ï¸ **[View Full Compact Summary](\($compact_file))**\n\n---\n"
                        else .message.content | clean_system_tags
                        end
                    end
                else null
                end
            )
        } | select(.content != null and .content != "")] |

        # Merge consecutive messages of same type / åˆå¹¶è¿ç»­ç›¸åŒç±»å‹çš„æ¶ˆæ¯
        reduce .[] as $item (
            [];
            if length == 0 then [$item]
            elif (last.type == $item.type) then
                (.[:-1] + [{type: $item.type, timestamp: last.timestamp, content: (last.content + "\n\n" + $item.content)}])
            else . + [$item]
            end
        ) |

        .[] |
        # Convert UTC to local timezone / UTC è½¬æœ¬åœ°æ—¶åŒº
        (.timestamp | if . then
            (.[11:13] | tonumber) as $h |
            (.[14:16]) as $m |
            (($h + $tz_offset) | if . >= 24 then . - 24 elif . < 0 then . + 24 else . end) as $new_h |
            "\($new_h | if . < 10 then "0\(.)" else "\(.)" end):\($m)"
        else "" end) as $time |
        if .type == "user" then
            "## ğŸ‘¤ User - \($time)\n\n\(.content)\n\n---\n"
        else
            "## ğŸ¤– Claude - \($time)\n\n\(.content)\n\n---\n"
        end
    ' "$jsonl_file" >> "$tmp_md_file" 2>/dev/null

    # Post-processing: clean system tags (multiline matching)
    # åå¤„ç†ï¼šæ¸…ç†ç³»ç»Ÿæ ‡ç­¾ï¼ˆå¤šè¡ŒåŒ¹é…ï¼‰
    perl -i -0pe 's/<system-reminder>.*?<\/system-reminder>\s*//gs' "$tmp_md_file" 2>/dev/null
    perl -i -0pe 's/<ide_opened_file>.*?<\/ide_opened_file>\s*//gs' "$tmp_md_file" 2>/dev/null
    perl -i -0pe 's/<user-prompt-submit-hook>.*?<\/user-prompt-submit-hook>\s*//gs' "$tmp_md_file" 2>/dev/null

    # Atomic update: delete old files first, then move temp files to target
    # åŸå­æ›´æ–°ï¼šå…ˆåˆ é™¤æ—§æ–‡ä»¶ï¼Œå†ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
    if [ -n "$old_file" ] && [ -f "$old_file" ] && [ "$old_file" != "$md_file" ]; then
        rm -f "$old_file" "$old_tools_file"
        old_compact_file=$(echo "$old_file" | sed 's/\[History\]/[Compact]/')
        rm -f "$old_compact_file"
    fi
    mv "$tmp_md_file" "$md_file"
    mv "$tmp_tools_file" "$tools_file"
    [ -f "$tmp_compact_file" ] && mv "$tmp_compact_file" "$compact_file"

done

# Generate index file (reverse chronological order, atomic update)
# ç”Ÿæˆç´¢å¼•æ–‡ä»¶ï¼ˆæŒ‰æ—¶é—´å€’åºï¼ŒåŸå­æ›´æ–°ï¼‰
generate_index() {
    local INDEX_FILE="$BACKUP_DIR/[Index]Sessions.md"
    local TMP_INDEX="$TMP_DIR/[Index]Sessions.md"
    cat > "$TMP_INDEX" << EOF
# Session History Index
> Last updated: $(date '+%Y-%m-%d %H:%M:%S')

| Time | Title | History | Tools |
|------|-------|---------|-------|
EOF
    for hist_file in $(ls -t "$BACKUP_DIR"/\[History\]*.md 2>/dev/null); do
        [ -f "$hist_file" ] || continue
        filename=$(basename "$hist_file")
        title=$(head -1 "$hist_file" | sed 's/^# //')
        file_time=$(echo "$filename" | grep -oE '[0-9]{2}-[0-9]{2}_[0-9]{4}' | head -1)
        [ -z "$file_time" ] && file_time="unknown"
        tools_file=$(echo "$filename" | sed 's/\[History\]/[ToolUse]/')
        # Full URL encoding (use python for Chinese and special chars)
        # å®Œæ•´ URL ç¼–ç ï¼ˆä½¿ç”¨ python å¤„ç†ä¸­æ–‡å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
        encoded_hist=$(python3 -c "import urllib.parse; print(urllib.parse.quote('$filename'))")
        encoded_tools=$(python3 -c "import urllib.parse; print(urllib.parse.quote('$tools_file'))")
        echo "| $file_time | $title | [History]($encoded_hist) | [Tools]($encoded_tools) |" >> "$TMP_INDEX"
    done
    mv "$TMP_INDEX" "$INDEX_FILE"
}

generate_index

echo "Last backup: $(date '+%Y-%m-%d %H:%M:%S')" > "$BACKUP_DIR/.last-backup"

# Clean up lock files / æ¸…ç†é”æ–‡ä»¶
if [ "$BACKGROUND_MODE" = "--background" ]; then
    rm -f "$BG_PID_FILE"
else
    rm -f "$LOCK_PID_FILE"
fi

exit 0
